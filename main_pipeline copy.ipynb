{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook will allow you to run a model on a single prepared dataset. \n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import ffmpeg\n",
    "import pdb\n",
    "from functions import create_pytorch_dataset\n",
    "from functions import get_window_metrics\n",
    "from functions import get_frame_metrics\n",
    "from functions import animate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  24  27  30  31  32  33  35  36  38  39  50  51  52  54  55  56\n",
      "  57  58  59  60  62  63  64  65  66  68  69  70  71  73  75  76  77  78\n",
      "  79  80  81  82  83  84  90  92  93  94  96  97  99 100 101 103 104 105\n",
      " 107 109 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 130 132 133 134 135 136 137 138 139 154 155 160 161 162 163 164\n",
      " 165 166 168 169 172 173 174 175 176 177 178 179 180 181 183 184 185 186\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 212 215 216 217 218 219 248 253 254 255 257 258 259 260\n",
      " 261 265 266 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282\n",
      " 283 284 285 286 287 288 289]\n",
      "['Fall0', 'Fall1', 'Fall10', 'Fall100', 'Fall101', 'Fall103', 'Fall104', 'Fall105', 'Fall107', 'Fall109', 'Fall11', 'Fall111', 'Fall112', 'Fall113', 'Fall114', 'Fall115', 'Fall116', 'Fall117', 'Fall118', 'Fall119', 'Fall12', 'Fall120', 'Fall121', 'Fall122', 'Fall123', 'Fall124', 'Fall125', 'Fall126', 'Fall127', 'Fall128', 'Fall13', 'Fall130', 'Fall132', 'Fall133', 'Fall134', 'Fall135', 'Fall136', 'Fall137', 'Fall138', 'Fall139', 'Fall14', 'Fall15', 'Fall154', 'Fall155', 'Fall16', 'Fall160', 'Fall161', 'Fall162', 'Fall163', 'Fall164', 'Fall165', 'Fall166', 'Fall168', 'Fall169', 'Fall17', 'Fall172', 'Fall173', 'Fall174', 'Fall175', 'Fall176', 'Fall177', 'Fall178', 'Fall179', 'Fall18', 'Fall180', 'Fall181', 'Fall183', 'Fall184', 'Fall185', 'Fall186', 'Fall189', 'Fall19', 'Fall190', 'Fall191', 'Fall192', 'Fall193', 'Fall194', 'Fall195', 'Fall196', 'Fall197', 'Fall198', 'Fall199', 'Fall2', 'Fall200', 'Fall201', 'Fall202', 'Fall203', 'Fall204', 'Fall205', 'Fall206', 'Fall207', 'Fall208', 'Fall209', 'Fall24', 'Fall248', 'Fall253', 'Fall254', 'Fall255', 'Fall257', 'Fall258', 'Fall259', 'Fall260', 'Fall261', 'Fall265', 'Fall266', 'Fall268', 'Fall269', 'Fall27', 'Fall270', 'Fall271', 'Fall272', 'Fall273', 'Fall274', 'Fall275', 'Fall276', 'Fall277', 'Fall278', 'Fall279', 'Fall280', 'Fall281', 'Fall282', 'Fall283', 'Fall284', 'Fall285', 'Fall286', 'Fall287', 'Fall288', 'Fall289', 'Fall3', 'Fall30', 'Fall31', 'Fall32', 'Fall33', 'Fall35', 'Fall36', 'Fall38', 'Fall39', 'Fall4', 'Fall5', 'Fall50', 'Fall51', 'Fall52', 'Fall54', 'Fall55', 'Fall56', 'Fall57', 'Fall58', 'Fall59', 'Fall6', 'Fall60', 'Fall62', 'Fall63', 'Fall64', 'Fall65', 'Fall66', 'Fall68', 'Fall69', 'Fall7', 'Fall70', 'Fall71', 'Fall73', 'Fall75', 'Fall76', 'Fall77', 'Fall78', 'Fall79', 'Fall8', 'Fall80', 'Fall81', 'Fall82', 'Fall83', 'Fall84', 'Fall9', 'Fall90', 'Fall92', 'Fall93', 'Fall94', 'Fall96', 'Fall97', 'Fall99']\n",
      "['NonFall10', 'NonFall11', 'NonFall12', 'NonFall13', 'NonFall14', 'NonFall15', 'NonFall16', 'NonFall17', 'NonFall18', 'NonFall19', 'NonFall20', 'NonFall22', 'NonFall23', 'NonFall24', 'NonFall25', 'NonFall26', 'NonFall27', 'NonFall28', 'NonFall29', 'NonFall60', 'NonFall61', 'NonFall62', 'NonFall63', 'NonFall64', 'NonFall65', 'NonFall66', 'NonFall67', 'NonFall68', 'NonFall69', 'NonFall70', 'NonFall71', 'NonFall72', 'NonFall73', 'NonFall74', 'NonFall75', 'NonFall76', 'NonFall77', 'NonFall78', 'NonFall79', 'NonFall80', 'NonFall81', 'NonFall82', 'NonFall83', 'NonFall84', 'NonFall85', 'NonFall86', 'NonFall87', 'NonFall88']\n",
      "Skipped Fall99\n",
      "Skipped Fall99\n",
      "Skipped Fall99\n",
      "Skipped Fall99\n",
      "Skipped Fall99\n",
      "180\n",
      "180\n",
      "43\n",
      "43\n",
      "['NonFall10', 'NonFall11', 'NonFall12', 'NonFall13', 'NonFall14', 'NonFall15', 'NonFall16', 'NonFall17', 'NonFall18', 'NonFall19', 'NonFall20', 'NonFall22', 'NonFall24', 'NonFall25', 'NonFall26', 'NonFall27', 'NonFall28', 'NonFall29', 'NonFall60', 'NonFall61', 'NonFall62', 'NonFall63', 'NonFall64', 'NonFall65', 'NonFall66', 'NonFall67', 'NonFall68', 'NonFall69', 'NonFall70', 'NonFall71', 'NonFall72', 'NonFall73', 'NonFall74', 'NonFall75', 'NonFall76', 'NonFall77', 'NonFall78', 'NonFall79', 'NonFall80', 'NonFall81', 'NonFall82', 'NonFall83', 'NonFall84']\n",
      "['Fall0', 'Fall1', 'Fall10', 'Fall100', 'Fall101', 'Fall103', 'Fall104', 'Fall105', 'Fall107', 'Fall109', 'Fall11', 'Fall111', 'Fall112', 'Fall113', 'Fall114', 'Fall115', 'Fall116', 'Fall117', 'Fall118', 'Fall119', 'Fall12', 'Fall120', 'Fall121', 'Fall122', 'Fall123', 'Fall124', 'Fall125', 'Fall126', 'Fall127', 'Fall128', 'Fall13', 'Fall130', 'Fall132', 'Fall133', 'Fall134', 'Fall135', 'Fall136', 'Fall137', 'Fall138', 'Fall139', 'Fall14', 'Fall15', 'Fall154', 'Fall155', 'Fall16', 'Fall160', 'Fall161', 'Fall162', 'Fall163', 'Fall164', 'Fall165', 'Fall166', 'Fall168', 'Fall169', 'Fall17', 'Fall172', 'Fall173', 'Fall174', 'Fall175', 'Fall176', 'Fall177', 'Fall178', 'Fall179', 'Fall18', 'Fall180', 'Fall181', 'Fall183', 'Fall184', 'Fall185', 'Fall186', 'Fall189', 'Fall19', 'Fall190', 'Fall191', 'Fall192', 'Fall193', 'Fall194', 'Fall195', 'Fall196', 'Fall197', 'Fall198', 'Fall199', 'Fall2', 'Fall200', 'Fall201', 'Fall202', 'Fall203', 'Fall204', 'Fall205', 'Fall206', 'Fall207', 'Fall208', 'Fall209', 'Fall24', 'Fall248', 'Fall253', 'Fall254', 'Fall255', 'Fall257', 'Fall258', 'Fall259', 'Fall260', 'Fall261', 'Fall265', 'Fall266', 'Fall268', 'Fall269', 'Fall27', 'Fall270', 'Fall271', 'Fall272', 'Fall273', 'Fall274', 'Fall275', 'Fall276', 'Fall277', 'Fall278', 'Fall279', 'Fall280', 'Fall281', 'Fall282', 'Fall283', 'Fall284', 'Fall285', 'Fall286', 'Fall287', 'Fall288', 'Fall289', 'Fall3', 'Fall30', 'Fall31', 'Fall32', 'Fall33', 'Fall35', 'Fall36', 'Fall38', 'Fall39', 'Fall4', 'Fall5', 'Fall50', 'Fall51', 'Fall52', 'Fall54', 'Fall55', 'Fall56', 'Fall57', 'Fall58', 'Fall59', 'Fall6', 'Fall60', 'Fall62', 'Fall63', 'Fall64', 'Fall65', 'Fall66', 'Fall68', 'Fall69', 'Fall7', 'Fall70', 'Fall71', 'Fall73', 'Fall75', 'Fall76', 'Fall77', 'Fall78', 'Fall79', 'Fall8', 'Fall80', 'Fall81', 'Fall82', 'Fall83', 'Fall84', 'Fall9', 'Fall90', 'Fall92', 'Fall93', 'Fall94', 'Fall96', 'Fall97', 'Fall99']\n",
      "   Participant  Trial  Video  Start  Stop  ToD  Ambigious Start\n",
      "0            1      1      0    768   770    0                0\n",
      "2            1      2      1    705   711    0                0\n",
      "3            1      3      2    615   626    0                0\n",
      "4            1      4      3    580   593    0                0\n",
      "5            1      5      4    606   617    0                0\n"
     ]
    }
   ],
   "source": [
    "# Lets load the H%PY dataset into a pytorch dataset class.Please see \n",
    "# dataset_creator on how to generate the H5PY file. \n",
    "\n",
    "# Name of the H5PY dataset \n",
    "dset = \"Edits/ONI_Depth\" #where the orginal data is stored \n",
    "name = \"ONI_Depth_Filled\" # name of the h5py file\n",
    "path = \"H5Data\\Data_set-{}-imgdim64x64.h5\".format(name) # location of the h5py file\n",
    "# this will also window the data at a set size, and with the set stride \n",
    "\n",
    "window_len = 8\n",
    "stride = 1\n",
    "fair_comparison = True\n",
    "\n",
    "Test_Dataset, test_dataloader, Train_Dataset, train_dataloader = create_pytorch_dataset(name, dset, path, window_len, fair_comparison, stride)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now that we have our datasets prepared, lets write our model \n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # first layer\n",
    "        self.ec1 = nn.Conv3d(1, 16, (5, 3, 3), stride=1, padding=(2, 1, 1),)\n",
    "        self.em1 = nn.MaxPool3d((1, 2, 2), return_indices=True)\n",
    "        #self.ed1 = nn.Dropout3d(p=0.25)\n",
    "        # second layer\n",
    "        self.ec2 = nn.Conv3d(16, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.em2 = nn.MaxPool3d((2, 2, 2), return_indices=True)\n",
    "        #self.ed2 = nn.Dropout3d(p=0.25)\n",
    "        # third layer\n",
    "        self.ec3 = nn.Conv3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.em3 = nn.MaxPool3d((2, 2, 2), return_indices=True)\n",
    "        # encoding done, time to decode\n",
    "        self.dc1 = nn.ConvTranspose3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        # inverse of 2nd Conv\n",
    "        self.dc2 = nn.ConvTranspose3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        # inverse of 1st Conv\n",
    "        self.dc3 = nn.ConvTranspose3d(8, 16, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm3 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        # final inverse\n",
    "        self.dc4 = nn.ConvTranspose3d(16, 1, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # *** start of encoder\n",
    "        x = x.permute(1, 0, 2, 3, 4)  # reorder to have correct dimensions\n",
    "        \n",
    "        # (batch_size, chanels, depth, width, height)\n",
    "        _ec1 = F.relu(self.ec1(x))\n",
    "        _em1, i1 = self.em1(_ec1)\n",
    "\n",
    "\n",
    "        #_em1 = self.ed1(_em1) # dropout layer\n",
    "        # second layer \n",
    "        _ec2 = F.relu(self.ec2(_em1))\n",
    "        _em2, i2 = self.em2(_ec2)\n",
    "        \n",
    "        #_em2 = self.ed2(_em2) # dropout layer\n",
    "        # third layer\n",
    "        _ec3 = F.relu(self.ec3(_em2))\n",
    "        _em3, i3 = self.em3(_ec3)\n",
    "     \n",
    "        # print(\"====== Encoding Done =========\")\n",
    "        # *** encoding done, time to decode\n",
    "        _dc1 = F.relu(self.dc1(_em3))\n",
    "        _dm1 = self.dm1(_dc1, i3, output_size=_em2.size())\n",
    "        \n",
    "        # second layer\n",
    "        _dc2 = F.relu(self.dc2(_dm1))\n",
    "        _dm2 = self.dm2(_dc2, i2)\n",
    "        \n",
    "        # third layer\n",
    "        _dc3 = F.relu(self.dc3(_dm2))\n",
    "        _dm3 = self.dm3(_dc3, i1)\n",
    "        \n",
    "        re_x = torch.tanh(self.dc4(_dm3))\n",
    "        '''\n",
    "        print(x.shape)\n",
    "        print(_ec1.shape)\n",
    "        print(_em1.shape)\n",
    "        print(_ec2.shape)\n",
    "        print(_em2.shape)\n",
    "        print(_ec3.shape)\n",
    "        print(_em3.shape)\n",
    "        print(_dc1.shape)\n",
    "        print(_dm1.shape)\n",
    "        print(_dc2.shape)\n",
    "        print(_dm2.shape)\n",
    "        print(_dc3.shape)\n",
    "        print(_dm3.shape)\n",
    "        print(re_x.shape)\n",
    "        '''\n",
    "        return re_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Now lets train our model\n",
    "\n",
    "# prepare for GPU training \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# and lets set the hyperparameters! \n",
    "\n",
    "dropout = 0.25\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20\n",
    "chunk_size = 128\n",
    "forward_chunk = 8 \n",
    "forward_chunk_size = 8 # this is smaller due to memory constrains \n",
    "\n",
    "# select which model - you could load your own or put it in the function above \n",
    "model = Autoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(filepath):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        val_loss = 0\n",
    "        for i, (sample, labels) in enumerate(train_dataloader):\n",
    "            # ===================forward=====================\n",
    "            sample = sample.to(device, dtype=torch.float)\n",
    "            # split sample into smaller sizes due to GPU memory constraints\n",
    "            chunks = torch.split(sample, chunk_size, dim=1)\n",
    "            for chunk in chunks:\n",
    "                output = model(chunk)\n",
    "                output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                model.zero_grad()\n",
    "                loss = loss_fn(output, chunk)\n",
    "                # ===================backward====================\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "                # Updating parameters\n",
    "                optimizer.step()\n",
    "                # Clear gradients w.r.t. parameters\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.empty_cache()\n",
    "        # ===================log========================\n",
    "        print(\"epoch [{}/{}], loss:{:.4f}\".format(epoch + 1, num_epochs, loss.item()))\n",
    "        torch.save(model.state_dict(), filepath) # save the model each epoch at location filepath\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def foward_pass(path):\n",
    "    model.load_state_dict(torch.load(path)) # load a saved model \n",
    "    model.eval()\n",
    "    frame_stats = [] \n",
    "    window_stats = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"foward pass occuring\")\n",
    "        # just forward pass of model on test dataset\n",
    "        for j, (sample, labels) in enumerate(test_dataloader):\n",
    "            print(j)\n",
    "            # foward pass to get output\n",
    "            torch.cuda.empty_cache()\n",
    "            sample = sample.to(device, dtype=torch.float)\n",
    "            chunks = torch.split(sample, forward_chunk, dim=1)\n",
    "            recon_vid = []\n",
    "            for chunk in chunks:\n",
    "                output = model(chunk)\n",
    "                output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                recon_vid.append(output)\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            output = torch.cat(recon_vid, dim=1)\n",
    "            # convert tensors to numpy arrays for easy manipluations\n",
    "            sample = sample.data.cpu().numpy()\n",
    "            output = output.data.cpu().numpy()\n",
    "            labels = labels.data.cpu().numpy()\n",
    "\n",
    "            frame_mean, frame_std, frame_labels = get_frame_metrics(output, sample, labels, window_len)\n",
    "            mean_window_error, std_window_error, window_labels = get_window_metrics(output, sample, labels, window_len)\n",
    "            frame_stats.append([frame_mean, frame_std, frame_labels])\n",
    "            window_stats.append([mean_window_error, std_window_error, window_labels])\n",
    "            '''\n",
    "            if j % 3 == 0:\n",
    "                animate(sample[0, :, :, :, :], output[0, :, :, :, :], frame_mean, dset, start_time)\n",
    "            '''\n",
    "            \n",
    "\n",
    "    return(frame_stats, window_stats)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-04-01-12-58-08\n",
      "Models\\Edits/ONI_DepthFair_RegularLoss2021-04-01-12-58-08\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([37, 1, 8, 64, 64])\n",
      "torch.Size([37, 16, 8, 64, 64])\n",
      "torch.Size([37, 16, 8, 32, 32])\n",
      "torch.Size([37, 8, 8, 32, 32])\n",
      "torch.Size([37, 8, 4, 16, 16])\n",
      "torch.Size([37, 8, 4, 16, 16])\n",
      "torch.Size([37, 8, 2, 8, 8])\n",
      "torch.Size([37, 8, 2, 8, 8])\n",
      "torch.Size([37, 8, 4, 16, 16])\n",
      "torch.Size([37, 8, 4, 16, 16])\n",
      "torch.Size([37, 8, 8, 32, 32])\n",
      "torch.Size([37, 16, 8, 32, 32])\n",
      "torch.Size([37, 16, 8, 64, 64])\n",
      "torch.Size([37, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([70, 1, 8, 64, 64])\n",
      "torch.Size([70, 16, 8, 64, 64])\n",
      "torch.Size([70, 16, 8, 32, 32])\n",
      "torch.Size([70, 8, 8, 32, 32])\n",
      "torch.Size([70, 8, 4, 16, 16])\n",
      "torch.Size([70, 8, 4, 16, 16])\n",
      "torch.Size([70, 8, 2, 8, 8])\n",
      "torch.Size([70, 8, 2, 8, 8])\n",
      "torch.Size([70, 8, 4, 16, 16])\n",
      "torch.Size([70, 8, 4, 16, 16])\n",
      "torch.Size([70, 8, 8, 32, 32])\n",
      "torch.Size([70, 16, 8, 32, 32])\n",
      "torch.Size([70, 16, 8, 64, 64])\n",
      "torch.Size([70, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([25, 1, 8, 64, 64])\n",
      "torch.Size([25, 16, 8, 64, 64])\n",
      "torch.Size([25, 16, 8, 32, 32])\n",
      "torch.Size([25, 8, 8, 32, 32])\n",
      "torch.Size([25, 8, 4, 16, 16])\n",
      "torch.Size([25, 8, 4, 16, 16])\n",
      "torch.Size([25, 8, 2, 8, 8])\n",
      "torch.Size([25, 8, 2, 8, 8])\n",
      "torch.Size([25, 8, 4, 16, 16])\n",
      "torch.Size([25, 8, 4, 16, 16])\n",
      "torch.Size([25, 8, 8, 32, 32])\n",
      "torch.Size([25, 16, 8, 32, 32])\n",
      "torch.Size([25, 16, 8, 64, 64])\n",
      "torch.Size([25, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 2, 8, 8])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 4, 16, 16])\n",
      "torch.Size([128, 8, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 32, 32])\n",
      "torch.Size([128, 16, 8, 64, 64])\n",
      "torch.Size([128, 1, 8, 64, 64])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d9777fe59662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#filepath = 'Models\\Edits\\ZED_DepthFair_RegularLoss2021-03-25-21-05-48'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manimate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-6ea5fa65c027>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;31m# ===================backward====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;31m# Getting gradients w.r.t. parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# Updating parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = str(datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "print(start_time)\n",
    "filepath = (\n",
    "    \"Models\\\\\"\n",
    "    + dset \n",
    "    + 'Fair_'\n",
    "    + 'RegularLoss'\n",
    "    + start_time\n",
    ")\n",
    "#filepath = 'Models\\Edits\\ZED_DepthFair_RegularLoss2021-03-25-21-05-48'\n",
    "print(filepath)\n",
    "train_model(filepath)\n",
    "import functions\n",
    "from functions import animate\n",
    "\n",
    "frame_stats, window_stats = foward_pass(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functions\n",
    "from functions import get_total_performance_metrics\n",
    "from importlib import reload\n",
    "reload(functions)\n",
    "from functions import get_total_performance_metrics\n",
    "\n",
    "get_total_performance_metrics(frame_stats, window_stats, window_len)\n",
    "\n",
    "\n",
    "#get_total_performance_metrics(originals, reconstruced, testing_labels, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}