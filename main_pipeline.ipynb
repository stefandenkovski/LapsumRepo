{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook will allow you to run a model on a single prepared dataset. \n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import ffmpeg\n",
    "import pdb\n",
    "from functions import create_pytorch_dataset\n",
    "from functions import get_window_metrics\n",
    "from functions import get_frame_metrics\n",
    "from functions import animate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Fall0', 'Fall1', 'Fall10', 'Fall100', 'Fall101', 'Fall102', 'Fall103', 'Fall104', 'Fall105', 'Fall106', 'Fall107', 'Fall108', 'Fall109', 'Fall11', 'Fall110', 'Fall111', 'Fall112', 'Fall113', 'Fall114', 'Fall115', 'Fall116', 'Fall117', 'Fall118', 'Fall119', 'Fall12', 'Fall120', 'Fall121', 'Fall122', 'Fall123', 'Fall124', 'Fall125', 'Fall126', 'Fall127', 'Fall128', 'Fall129', 'Fall13', 'Fall130', 'Fall131', 'Fall132', 'Fall133', 'Fall134', 'Fall135', 'Fall136', 'Fall137', 'Fall138', 'Fall139', 'Fall14', 'Fall140', 'Fall141', 'Fall142', 'Fall143', 'Fall144', 'Fall145', 'Fall146', 'Fall147', 'Fall148', 'Fall149', 'Fall15', 'Fall150', 'Fall151', 'Fall152', 'Fall153', 'Fall154', 'Fall155', 'Fall156', 'Fall157', 'Fall158', 'Fall159', 'Fall16', 'Fall160', 'Fall161', 'Fall162', 'Fall163', 'Fall164', 'Fall165', 'Fall166', 'Fall167', 'Fall168', 'Fall169', 'Fall17', 'Fall170', 'Fall171', 'Fall172', 'Fall173', 'Fall174', 'Fall175', 'Fall176', 'Fall177', 'Fall178', 'Fall179', 'Fall18', 'Fall180', 'Fall181', 'Fall182', 'Fall183', 'Fall184', 'Fall185', 'Fall186', 'Fall187', 'Fall188', 'Fall189', 'Fall19', 'Fall190', 'Fall191', 'Fall192', 'Fall193', 'Fall194', 'Fall195', 'Fall196', 'Fall197', 'Fall198', 'Fall199', 'Fall2', 'Fall20', 'Fall200', 'Fall201', 'Fall202', 'Fall203', 'Fall204', 'Fall205', 'Fall206', 'Fall207', 'Fall208', 'Fall209', 'Fall22', 'Fall220', 'Fall221', 'Fall222', 'Fall223', 'Fall224', 'Fall225', 'Fall226', 'Fall227', 'Fall228', 'Fall229', 'Fall230', 'Fall231', 'Fall232', 'Fall233', 'Fall234', 'Fall235', 'Fall236', 'Fall237', 'Fall238', 'Fall239', 'Fall24', 'Fall248', 'Fall249', 'Fall25', 'Fall252', 'Fall253', 'Fall254', 'Fall255', 'Fall256', 'Fall257', 'Fall258', 'Fall259', 'Fall26', 'Fall260', 'Fall261', 'Fall265', 'Fall266', 'Fall267', 'Fall268', 'Fall269', 'Fall27', 'Fall270', 'Fall271', 'Fall272', 'Fall273', 'Fall274', 'Fall275', 'Fall276', 'Fall277', 'Fall278', 'Fall279', 'Fall28', 'Fall280', 'Fall281', 'Fall282', 'Fall283', 'Fall284', 'Fall285', 'Fall286', 'Fall287', 'Fall288', 'Fall289', 'Fall29', 'Fall3', 'Fall30', 'Fall31', 'Fall32', 'Fall33', 'Fall34', 'Fall35', 'Fall36', 'Fall37', 'Fall38', 'Fall39', 'Fall4', 'Fall40', 'Fall41', 'Fall43', 'Fall44', 'Fall45', 'Fall46', 'Fall47', 'Fall48', 'Fall49', 'Fall5', 'Fall50', 'Fall51', 'Fall52', 'Fall54', 'Fall55', 'Fall56', 'Fall57', 'Fall58', 'Fall59', 'Fall6', 'Fall60', 'Fall61', 'Fall62', 'Fall63', 'Fall64', 'Fall65', 'Fall66', 'Fall67', 'Fall68', 'Fall69', 'Fall7', 'Fall70', 'Fall71', 'Fall72', 'Fall73', 'Fall74', 'Fall75', 'Fall76', 'Fall77', 'Fall78', 'Fall79', 'Fall8', 'Fall80', 'Fall81', 'Fall82', 'Fall83', 'Fall84', 'Fall9', 'Fall90', 'Fall91', 'Fall92', 'Fall93', 'Fall94', 'Fall95', 'Fall96', 'Fall97', 'Fall98', 'Fall99']\n",
      "['NonFall10', 'NonFall11', 'NonFall12', 'NonFall13', 'NonFall14', 'NonFall15', 'NonFall16', 'NonFall17', 'NonFall18', 'NonFall19', 'NonFall20', 'NonFall22', 'NonFall23', 'NonFall24', 'NonFall25', 'NonFall26', 'NonFall27', 'NonFall28', 'NonFall29', 'NonFall50', 'NonFall51', 'NonFall52', 'NonFall53', 'NonFall54', 'NonFall55', 'NonFall56', 'NonFall57', 'NonFall58', 'NonFall59', 'NonFall60', 'NonFall61', 'NonFall62', 'NonFall63', 'NonFall64', 'NonFall65', 'NonFall66', 'NonFall67', 'NonFall68', 'NonFall69', 'NonFall70', 'NonFall71', 'NonFall72', 'NonFall73', 'NonFall74', 'NonFall75', 'NonFall76', 'NonFall77', 'NonFall78', 'NonFall79', 'NonFall80', 'NonFall81', 'NonFall82', 'NonFall83', 'NonFall84', 'NonFall85', 'NonFall86', 'NonFall87', 'NonFall88', 'NonFall90', 'NonFall91', 'NonFall92', 'NonFall93', 'NonFall94', 'NonFall95', 'NonFall96', 'NonFall97', 'NonFall98', 'NonFall99']\n",
      "258\n",
      "258\n",
      "68\n",
      "68\n",
      "['NonFall10', 'NonFall11', 'NonFall12', 'NonFall13', 'NonFall14', 'NonFall15', 'NonFall16', 'NonFall17', 'NonFall18', 'NonFall19', 'NonFall20', 'NonFall22', 'NonFall23', 'NonFall24', 'NonFall25', 'NonFall26', 'NonFall27', 'NonFall28', 'NonFall29', 'NonFall50', 'NonFall51', 'NonFall52', 'NonFall53', 'NonFall54', 'NonFall55', 'NonFall56', 'NonFall57', 'NonFall58', 'NonFall59', 'NonFall60', 'NonFall61', 'NonFall62', 'NonFall63', 'NonFall64', 'NonFall65', 'NonFall66', 'NonFall67', 'NonFall68', 'NonFall69', 'NonFall70', 'NonFall71', 'NonFall72', 'NonFall73', 'NonFall74', 'NonFall75', 'NonFall76', 'NonFall77', 'NonFall78', 'NonFall79', 'NonFall80', 'NonFall81', 'NonFall82', 'NonFall83', 'NonFall84', 'NonFall85', 'NonFall86', 'NonFall87', 'NonFall88', 'NonFall90', 'NonFall91', 'NonFall92', 'NonFall93', 'NonFall94', 'NonFall95', 'NonFall96', 'NonFall97', 'NonFall98', 'NonFall99']\n",
      "['Fall0', 'Fall1', 'Fall10', 'Fall100', 'Fall101', 'Fall102', 'Fall103', 'Fall104', 'Fall105', 'Fall106', 'Fall107', 'Fall108', 'Fall109', 'Fall11', 'Fall110', 'Fall111', 'Fall112', 'Fall113', 'Fall114', 'Fall115', 'Fall116', 'Fall117', 'Fall118', 'Fall119', 'Fall12', 'Fall120', 'Fall121', 'Fall122', 'Fall123', 'Fall124', 'Fall125', 'Fall126', 'Fall127', 'Fall128', 'Fall129', 'Fall13', 'Fall130', 'Fall131', 'Fall132', 'Fall133', 'Fall134', 'Fall135', 'Fall136', 'Fall137', 'Fall138', 'Fall139', 'Fall14', 'Fall140', 'Fall141', 'Fall142', 'Fall143', 'Fall144', 'Fall145', 'Fall146', 'Fall147', 'Fall148', 'Fall149', 'Fall15', 'Fall150', 'Fall151', 'Fall152', 'Fall153', 'Fall154', 'Fall155', 'Fall156', 'Fall157', 'Fall158', 'Fall159', 'Fall16', 'Fall160', 'Fall161', 'Fall162', 'Fall163', 'Fall164', 'Fall165', 'Fall166', 'Fall167', 'Fall168', 'Fall169', 'Fall17', 'Fall170', 'Fall171', 'Fall172', 'Fall173', 'Fall174', 'Fall175', 'Fall176', 'Fall177', 'Fall178', 'Fall179', 'Fall18', 'Fall180', 'Fall181', 'Fall182', 'Fall183', 'Fall184', 'Fall185', 'Fall186', 'Fall187', 'Fall188', 'Fall189', 'Fall19', 'Fall190', 'Fall191', 'Fall192', 'Fall193', 'Fall194', 'Fall195', 'Fall196', 'Fall197', 'Fall198', 'Fall199', 'Fall2', 'Fall20', 'Fall200', 'Fall201', 'Fall202', 'Fall203', 'Fall204', 'Fall205', 'Fall206', 'Fall207', 'Fall208', 'Fall209', 'Fall22', 'Fall220', 'Fall221', 'Fall222', 'Fall223', 'Fall224', 'Fall225', 'Fall226', 'Fall227', 'Fall228', 'Fall229', 'Fall230', 'Fall231', 'Fall232', 'Fall233', 'Fall234', 'Fall235', 'Fall236', 'Fall237', 'Fall238', 'Fall239', 'Fall24', 'Fall248', 'Fall249', 'Fall25', 'Fall252', 'Fall253', 'Fall254', 'Fall255', 'Fall256', 'Fall257', 'Fall258', 'Fall259', 'Fall26', 'Fall260', 'Fall261', 'Fall265', 'Fall266', 'Fall267', 'Fall268', 'Fall269', 'Fall27', 'Fall270', 'Fall271', 'Fall272', 'Fall273', 'Fall274', 'Fall275', 'Fall276', 'Fall277', 'Fall278', 'Fall279', 'Fall28', 'Fall280', 'Fall281', 'Fall282', 'Fall283', 'Fall284', 'Fall285', 'Fall286', 'Fall287', 'Fall288', 'Fall289', 'Fall29', 'Fall3', 'Fall30', 'Fall31', 'Fall32', 'Fall33', 'Fall34', 'Fall35', 'Fall36', 'Fall37', 'Fall38', 'Fall39', 'Fall4', 'Fall40', 'Fall41', 'Fall43', 'Fall44', 'Fall45', 'Fall46', 'Fall47', 'Fall48', 'Fall49', 'Fall5', 'Fall50', 'Fall51', 'Fall52', 'Fall54', 'Fall55', 'Fall56', 'Fall57', 'Fall58', 'Fall59', 'Fall6', 'Fall60', 'Fall61', 'Fall62', 'Fall63', 'Fall64', 'Fall65', 'Fall66', 'Fall67', 'Fall68', 'Fall69', 'Fall7', 'Fall70', 'Fall71', 'Fall72', 'Fall73', 'Fall74', 'Fall75', 'Fall76', 'Fall77', 'Fall78', 'Fall79', 'Fall8', 'Fall80', 'Fall81', 'Fall82', 'Fall83', 'Fall84', 'Fall9', 'Fall90', 'Fall91', 'Fall92', 'Fall93', 'Fall94', 'Fall95', 'Fall96', 'Fall97', 'Fall98', 'Fall99']\n",
      "   Participant  Trial  Video  Start  Stop  ToD  Ambigious Start\n",
      "0            1      1      0    768   770    0                0\n",
      "2            1      2      1    705   711    0                0\n",
      "3            1      3      2    615   626    0                0\n",
      "4            1      4      3    580   593    0                0\n",
      "5            1      5      4    606   617    0                0\n"
     ]
    }
   ],
   "source": [
    "# Lets load the H%PY dataset into a pytorch dataset class.Please see \n",
    "# dataset_creator on how to generate the H5PY file. \n",
    "\n",
    "# Name of the H5PY dataset \n",
    "dset = \"Edits/ONI_IR\" #where the orginal data is stored \n",
    "name = \"ONI_IR_Edit\" # name of the h5py file\n",
    "path = \"H5Data\\Data_set-{}-imgdim64x64.h5\".format(name) # location of the h5py file\n",
    "# this will also window the data at a set size, and with the set stride \n",
    "\n",
    "window_len = 8\n",
    "stride = 1\n",
    "\n",
    "Test_Dataset, test_dataloader, Train_Dataset, train_dataloader = create_pytorch_dataset(name, dset, path, window_len, stride)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now that we have our datasets prepared, lets write our model \n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # first layer\n",
    "        self.ec1 = nn.Conv3d(1, 16, (5, 3, 3), stride=1, padding=(2, 1, 1),)\n",
    "        self.em1 = nn.MaxPool3d((1, 2, 2), return_indices=True)\n",
    "        self.ed1 = nn.Dropout3d(p=0.25)\n",
    "        # second layer\n",
    "        self.ec2 = nn.Conv3d(16, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.em2 = nn.MaxPool3d((2, 2, 2), return_indices=True)\n",
    "        self.ed2 = nn.Dropout3d(p=0.25)\n",
    "        # third layer\n",
    "        self.ec3 = nn.Conv3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.em3 = nn.MaxPool3d((2, 2, 2), return_indices=True)\n",
    "        # encoding done, time to decode\n",
    "        self.dc1 = nn.ConvTranspose3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm1 = nn.MaxUnpool3d((2, 2, 2))\n",
    "        # inverse of 2nd Conv\n",
    "        self.dc2 = nn.ConvTranspose3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm2 = nn.MaxUnpool3d((2, 2, 2))\n",
    "        # inverse of 1st Conv\n",
    "        self.dc3 = nn.ConvTranspose3d(8, 16, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm3 = nn.MaxUnpool3d((1, 2, 2))\n",
    "        # final inverse\n",
    "        self.dc4 = nn.ConvTranspose3d(16, 1, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # *** start of encoder\n",
    "        x = x.permute(1, 0, 2, 3, 4)  # reorder to have correct dimensions\n",
    "        # (batch_size, chanels, depth, width, height)\n",
    "        _ec1 = F.relu(self.ec1(x))\n",
    "        _em1, i1 =         self.em1(_ec1)\n",
    "        _ec1 = self.ed1(_ec1)\n",
    "        # second layer\n",
    "        _ec2 = F.relu(self.ec2(_em1))\n",
    "        _em2, i2 = self.em2(_ec2)\n",
    "        _em2 = self.ed2(_em2)\n",
    "        # third layer\n",
    "        _ec3 = F.relu(self.ec3(_em2))\n",
    "        _em3, i3 = self.em3(_ec3)\n",
    "        # print(\"====== Encoding Done =========\")\n",
    "        # *** encoding done, time to decode\n",
    "        _dc1 = F.relu(self.dc1(_em3))\n",
    "        _dm1 = self.dm1(_dc1, i3, output_size=_em2.size())\n",
    "        # second layer\n",
    "        _dc2 = F.relu(self.dc2(_dm1))\n",
    "        _dm2 = self.dm2(_dc2, i2)\n",
    "        # third layer\n",
    "        _dc3 = F.relu(self.dc3(_dm2))\n",
    "        _dm3 = self.dm3(_dc3, i1)\n",
    "\n",
    "        re_x = torch.tanh(self.dc4(_dm3))\n",
    "        return re_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Now lets train our model\n",
    "\n",
    "# prepare for GPU training \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# and lets set the hyperparameters! \n",
    "\n",
    "dropout = 0.25\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20\n",
    "chunk_size = 64\n",
    "forward_chunk = 8 \n",
    "forward_chunk_size = 8 # this is smaller due to memory constrains \n",
    "\n",
    "# select which model - you could load your own or put it in the function above \n",
    "model = Autoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(filepath):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        val_loss = 0\n",
    "        for i, (sample, labels) in enumerate(train_dataloader):\n",
    "            # ===================forward=====================\n",
    "            sample = sample.to(device, dtype=torch.float)\n",
    "            # split sample into smaller sizes due to GPU memory constraints\n",
    "            chunks = torch.split(sample, chunk_size, dim=1)\n",
    "            for chunk in chunks:\n",
    "                output = model(chunk)\n",
    "                output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                model.zero_grad()\n",
    "                loss = loss_fn(output, chunk)\n",
    "                # ===================backward====================\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "                # Updating parameters\n",
    "                optimizer.step()\n",
    "                # Clear gradients w.r.t. parameters\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # ===================log========================\n",
    "        print(\"epoch [{}/{}], loss:{:.4f}\".format(epoch + 1, num_epochs, loss.item()))\n",
    "        torch.save(model.state_dict(), filepath) # save the model each epoch at location filepath\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def foward_pass(path):\n",
    "    model.load_state_dict(torch.load(path)) # load a saved model \n",
    "    model.eval()\n",
    "    frame_stats = [] \n",
    "    window_stats = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"foward pass occuring\")\n",
    "        # just forward pass of model on test dataset\n",
    "        for j, (sample, labels) in enumerate(test_dataloader):\n",
    "            print(j)\n",
    "            # foward pass to get output\n",
    "            torch.cuda.empty_cache()\n",
    "            sample = sample.to(device, dtype=torch.float)\n",
    "            chunks = torch.split(sample, forward_chunk, dim=1)\n",
    "            recon_vid = []\n",
    "            for chunk in chunks:\n",
    "                output = model(chunk)\n",
    "                output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                recon_vid.append(output)\n",
    "                torch.cuda.empty_cache()\n",
    "   \n",
    "            output = torch.cat(recon_vid, dim=1)\n",
    "            # convert tensors to numpy arrays for easy manipluations\n",
    "            sample = sample.data.cpu().numpy()\n",
    "            output = output.data.cpu().numpy()\n",
    "            labels = labels.data.cpu().numpy()\n",
    "\n",
    "            frame_mean, frame_std, frame_labels = get_frame_metrics(output, sample, labels, window_len)\n",
    "            mean_window_error, std_window_error, window_labels = get_window_metrics(output, sample, labels, window_len)\n",
    "            frame_stats.append([frame_mean, frame_std, frame_labels])\n",
    "            window_stats.append([mean_window_error, std_window_error, window_labels])\n",
    "            '''\n",
    "            if j % 50 == 0:\n",
    "                animate(sample[0, :, :, :, :], output[0, :, :, :, :], frame_mean, dset, start_time)\n",
    "            '''\n",
    "            \n",
    "\n",
    "    return(frame_stats, window_stats)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-09-15-38-38\nModels\\Edits/ONI_IRRegularLoss2020-12-09-15-38-38\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-87acfe508833>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#filepath = 'Models\\Edits\\ONI_Depth2020-11-26-10-07-38'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manimate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-42bc98caa1f7>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[1;31m# ===================forward=====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = str(datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "print(start_time)\n",
    "filepath = (\n",
    "    \"Models\\\\\"\n",
    "    + dset \n",
    "    + 'RegularLoss'\n",
    "    + start_time\n",
    ")\n",
    "#filepath = 'Models\\Edits\\ONI_Depth2020-11-26-10-07-38'\n",
    "print(filepath)\n",
    "train_model(filepath)\n",
    "import functions\n",
    "from functions import animate\n",
    "\n",
    "\n",
    "frame_stats, window_stats = foward_pass(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(280, 5, 8)\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "from functions import get_total_performance_metrics\n",
    "from importlib import reload\n",
    "reload(functions)\n",
    "from functions import get_total_performance_metrics\n",
    "\n",
    "get_total_performance_metrics(frame_stats, window_stats, window_len)\n",
    "\n",
    "\n",
    "#get_total_performance_metrics(originals, reconstruced, testing_labels, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}