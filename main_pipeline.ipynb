{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook will allow you to run a model on a single prepared dataset. \n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import ffmpeg\n",
    "import pdb\n",
    "from functions import create_pytorch_dataset\n",
    "from functions import get_window_metrics\n",
    "from functions import get_frame_metrics\n",
    "from functions import animate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  24  27  30  31  32  33  35  36  38  39  50  51  52  54  55  56\n",
      "  57  58  59  60  62  63  64  65  66  68  69  70  71  73  75  76  77  78\n",
      "  79  80  81  82  83  84  90  92  93  94  96  97  99 100 101 103 104 105\n",
      " 107 109 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 130 132 133 134 135 136 137 138 139 154 155 160 161 162 163 164\n",
      " 165 166 168 169 172 173 174 175 176 177 178 179 180 181 183 184 185 186\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 212 215 216 217 218 219 248 253 254 255 257 258 259 260\n",
      " 261 265 266 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282\n",
      " 283 284 285 286 287 288 289]\n",
      "['Fall0', 'Fall1', 'Fall10', 'Fall100', 'Fall101', 'Fall103', 'Fall104', 'Fall105', 'Fall107', 'Fall109', 'Fall11', 'Fall111', 'Fall112', 'Fall113', 'Fall114', 'Fall115', 'Fall116', 'Fall117', 'Fall118', 'Fall119', 'Fall12', 'Fall120', 'Fall121', 'Fall122', 'Fall123', 'Fall124', 'Fall125', 'Fall126', 'Fall127', 'Fall128', 'Fall13', 'Fall130', 'Fall132', 'Fall133', 'Fall134', 'Fall135', 'Fall136', 'Fall137', 'Fall138', 'Fall139', 'Fall14', 'Fall15', 'Fall154', 'Fall155', 'Fall16', 'Fall160', 'Fall161', 'Fall162', 'Fall163', 'Fall164', 'Fall165', 'Fall166', 'Fall168', 'Fall169', 'Fall17', 'Fall172', 'Fall173', 'Fall174', 'Fall175', 'Fall176', 'Fall177', 'Fall178', 'Fall179', 'Fall18', 'Fall180', 'Fall181', 'Fall183', 'Fall184', 'Fall185', 'Fall186', 'Fall189', 'Fall19', 'Fall190', 'Fall191', 'Fall192', 'Fall193', 'Fall194', 'Fall195', 'Fall196', 'Fall197', 'Fall198', 'Fall199', 'Fall2', 'Fall200', 'Fall201', 'Fall202', 'Fall203', 'Fall204', 'Fall205', 'Fall206', 'Fall207', 'Fall208', 'Fall209', 'Fall210', 'Fall212', 'Fall215', 'Fall216', 'Fall217', 'Fall218', 'Fall219', 'Fall24', 'Fall248', 'Fall253', 'Fall254', 'Fall255', 'Fall257', 'Fall258', 'Fall259', 'Fall260', 'Fall261', 'Fall265', 'Fall266', 'Fall268', 'Fall269', 'Fall27', 'Fall270', 'Fall271', 'Fall272', 'Fall273', 'Fall274', 'Fall275', 'Fall276', 'Fall277', 'Fall278', 'Fall279', 'Fall280', 'Fall281', 'Fall282', 'Fall283', 'Fall284', 'Fall285', 'Fall286', 'Fall287', 'Fall288', 'Fall289', 'Fall3', 'Fall30', 'Fall31', 'Fall32', 'Fall33', 'Fall35', 'Fall36', 'Fall38', 'Fall39', 'Fall4', 'Fall5', 'Fall50', 'Fall51', 'Fall52', 'Fall54', 'Fall55', 'Fall56', 'Fall57', 'Fall58', 'Fall59', 'Fall6', 'Fall60', 'Fall62', 'Fall63', 'Fall64', 'Fall65', 'Fall66', 'Fall68', 'Fall69', 'Fall7', 'Fall70', 'Fall71', 'Fall73', 'Fall75', 'Fall76', 'Fall77', 'Fall78', 'Fall79', 'Fall8', 'Fall80', 'Fall81', 'Fall82', 'Fall83', 'Fall84', 'Fall9', 'Fall90', 'Fall92', 'Fall93', 'Fall94', 'Fall96', 'Fall97', 'Fall99']\n",
      "[]\n",
      "187\n",
      "187\n",
      "0\n",
      "0\n",
      "[]\n",
      "['Fall0', 'Fall1', 'Fall10', 'Fall100', 'Fall101', 'Fall103', 'Fall104', 'Fall105', 'Fall107', 'Fall109', 'Fall11', 'Fall111', 'Fall112', 'Fall113', 'Fall114', 'Fall115', 'Fall116', 'Fall117', 'Fall118', 'Fall119', 'Fall12', 'Fall120', 'Fall121', 'Fall122', 'Fall123', 'Fall124', 'Fall125', 'Fall126', 'Fall127', 'Fall128', 'Fall13', 'Fall130', 'Fall132', 'Fall133', 'Fall134', 'Fall135', 'Fall136', 'Fall137', 'Fall138', 'Fall139', 'Fall14', 'Fall15', 'Fall154', 'Fall155', 'Fall16', 'Fall160', 'Fall161', 'Fall162', 'Fall163', 'Fall164', 'Fall165', 'Fall166', 'Fall168', 'Fall169', 'Fall17', 'Fall172', 'Fall173', 'Fall174', 'Fall175', 'Fall176', 'Fall177', 'Fall178', 'Fall179', 'Fall18', 'Fall180', 'Fall181', 'Fall183', 'Fall184', 'Fall185', 'Fall186', 'Fall189', 'Fall19', 'Fall190', 'Fall191', 'Fall192', 'Fall193', 'Fall194', 'Fall195', 'Fall196', 'Fall197', 'Fall198', 'Fall199', 'Fall2', 'Fall200', 'Fall201', 'Fall202', 'Fall203', 'Fall204', 'Fall205', 'Fall206', 'Fall207', 'Fall208', 'Fall209', 'Fall210', 'Fall212', 'Fall215', 'Fall216', 'Fall217', 'Fall218', 'Fall219', 'Fall24', 'Fall248', 'Fall253', 'Fall254', 'Fall255', 'Fall257', 'Fall258', 'Fall259', 'Fall260', 'Fall261', 'Fall265', 'Fall266', 'Fall268', 'Fall269', 'Fall27', 'Fall270', 'Fall271', 'Fall272', 'Fall273', 'Fall274', 'Fall275', 'Fall276', 'Fall277', 'Fall278', 'Fall279', 'Fall280', 'Fall281', 'Fall282', 'Fall283', 'Fall284', 'Fall285', 'Fall286', 'Fall287', 'Fall288', 'Fall289', 'Fall3', 'Fall30', 'Fall31', 'Fall32', 'Fall33', 'Fall35', 'Fall36', 'Fall38', 'Fall39', 'Fall4', 'Fall5', 'Fall50', 'Fall51', 'Fall52', 'Fall54', 'Fall55', 'Fall56', 'Fall57', 'Fall58', 'Fall59', 'Fall6', 'Fall60', 'Fall62', 'Fall63', 'Fall64', 'Fall65', 'Fall66', 'Fall68', 'Fall69', 'Fall7', 'Fall70', 'Fall71', 'Fall73', 'Fall75', 'Fall76', 'Fall77', 'Fall78', 'Fall79', 'Fall8', 'Fall80', 'Fall81', 'Fall82', 'Fall83', 'Fall84', 'Fall9', 'Fall90', 'Fall92', 'Fall93', 'Fall94', 'Fall96', 'Fall97', 'Fall99']\n",
      "   Participant  Trial  Video  Start  Stop  ToD  FallLength\n",
      "0            1      1      0   1011  1018    0          13\n",
      "2            1      2      1   1133  1138    0           9\n",
      "3            1      3      2    716   723    0          13\n",
      "4            1      4      3    676   686    0          19\n",
      "5            1      5      4    707   712    0           8\n"
     ]
    }
   ],
   "source": [
    "# Lets load the H%PY dataset into a pytorch dataset class.Please see \n",
    "# dataset_creator on how to generate the H5PY file. \n",
    "\n",
    "# Name of the H5PY dataset \n",
    "dset = \"Edits/IP\" #where the orginal data is stored \n",
    "name = \"IP_Edit\" # name of the h5py file\n",
    "path = \"H5Data\\Data_set-{}-imgdim64x64.h5\".format(name) # location of the h5py file\n",
    "# this will also window the data at a set size, and with the set stride \n",
    "\n",
    "window_len = 8\n",
    "stride = 1\n",
    "fair_comparison = True\n",
    "\n",
    "Test_Dataset, test_dataloader, Train_Dataset, train_dataloader = create_pytorch_dataset(name, dset, path, window_len, fair_comparison, stride)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now that we have our datasets prepared, lets write our model \n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # first layer\n",
    "        self.ec1 = nn.Conv3d(1, 16, (5, 3, 3), stride=1, padding=(2, 1, 1),)\n",
    "        self.em1 = nn.MaxPool3d((1, 2, 2), return_indices=True)\n",
    "        #self.ed1 = nn.Dropout3d(p=0.25)\n",
    "        # second layer\n",
    "        self.ec2 = nn.Conv3d(16, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.em2 = nn.MaxPool3d((2, 2, 2), return_indices=True)\n",
    "        #self.ed2 = nn.Dropout3d(p=0.25)\n",
    "        # third layer\n",
    "        self.ec3 = nn.Conv3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.em3 = nn.MaxPool3d((2, 2, 2), return_indices=True)\n",
    "        # encoding done, time to decode\n",
    "        self.dc1 = nn.ConvTranspose3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm1 = nn.MaxUnpool3d((2, 2, 2))\n",
    "        # inverse of 2nd Conv\n",
    "        self.dc2 = nn.ConvTranspose3d(8, 8, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm2 = nn.MaxUnpool3d((2, 2, 2))\n",
    "        # inverse of 1st Conv\n",
    "        self.dc3 = nn.ConvTranspose3d(8, 16, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "        self.dm3 = nn.MaxUnpool3d((1, 2, 2))\n",
    "        # final inverse\n",
    "        self.dc4 = nn.ConvTranspose3d(16, 1, (5, 3, 3), stride=1, padding=(2, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # *** start of encoder\n",
    "        x = x.permute(1, 0, 2, 3, 4)  # reorder to have correct dimensions\n",
    "        # (batch_size, chanels, depth, width, height)\n",
    "        _ec1 = F.relu(self.ec1(x))\n",
    "        _em1, i1 =         self.em1(_ec1)\n",
    "        #_em1 = self.ed1(_em1) # dropout layer\n",
    "        # second layer \n",
    "        _ec2 = F.relu(self.ec2(_em1))\n",
    "        _em2, i2 = self.em2(_ec2)\n",
    "        #_em2 = self.ed2(_em2) # dropout layer\n",
    "        # third layer\n",
    "        _ec3 = F.relu(self.ec3(_em2))\n",
    "        _em3, i3 = self.em3(_ec3)\n",
    "        # print(\"====== Encoding Done =========\")\n",
    "        # *** encoding done, time to decode\n",
    "        _dc1 = F.relu(self.dc1(_em3))\n",
    "        _dm1 = self.dm1(_dc1, i3, output_size=_em2.size())\n",
    "        # second layer\n",
    "        _dc2 = F.relu(self.dc2(_dm1))\n",
    "        _dm2 = self.dm2(_dc2, i2)\n",
    "        # third layer\n",
    "        _dc3 = F.relu(self.dc3(_dm2))\n",
    "        _dm3 = self.dm3(_dc3, i1)\n",
    "\n",
    "        re_x = torch.tanh(self.dc4(_dm3))\n",
    "        return re_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Now lets train our model\n",
    "\n",
    "# prepare for GPU training \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# and lets set the hyperparameters! \n",
    "\n",
    "dropout = 0.25\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20\n",
    "chunk_size = 128\n",
    "forward_chunk = 8 \n",
    "forward_chunk_size = 8 # this is smaller due to memory constrains \n",
    "\n",
    "# select which model - you could load your own or put it in the function above \n",
    "model = Autoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(filepath):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        val_loss = 0\n",
    "        for i, (sample, labels) in enumerate(train_dataloader):\n",
    "            # ===================forward=====================\n",
    "            sample = sample.to(device, dtype=torch.float)\n",
    "            # split sample into smaller sizes due to GPU memory constraints\n",
    "            chunks = torch.split(sample, chunk_size, dim=1)\n",
    "            for chunk in chunks:\n",
    "                output = model(chunk)\n",
    "                output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                model.zero_grad()\n",
    "                loss = loss_fn(output, chunk)\n",
    "                # ===================backward====================\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "                # Updating parameters\n",
    "                optimizer.step()\n",
    "                # Clear gradients w.r.t. parameters\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # ===================log========================\n",
    "        print(\"epoch [{}/{}], loss:{:.4f}\".format(epoch + 1, num_epochs, loss.item()))\n",
    "        torch.save(model.state_dict(), filepath) # save the model each epoch at location filepath\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def foward_pass(path):\n",
    "    model.load_state_dict(torch.load(path)) # load a saved model \n",
    "    model.eval()\n",
    "    frame_stats = [] \n",
    "    window_stats = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"foward pass occuring\")\n",
    "        # just forward pass of model on test dataset\n",
    "        for j, (sample, labels) in enumerate(test_dataloader):\n",
    "            print(j)\n",
    "            # foward pass to get output\n",
    "            torch.cuda.empty_cache()\n",
    "            sample = sample.to(device, dtype=torch.float)\n",
    "            chunks = torch.split(sample, forward_chunk, dim=1)\n",
    "            recon_vid = []\n",
    "            for chunk in chunks:\n",
    "                output = model(chunk)\n",
    "                output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                recon_vid.append(output)\n",
    "                torch.cuda.empty_cache()\n",
    "   \n",
    "            output = torch.cat(recon_vid, dim=1)\n",
    "            # convert tensors to numpy arrays for easy manipluations\n",
    "            sample = sample.data.cpu().numpy()\n",
    "            output = output.data.cpu().numpy()\n",
    "            labels = labels.data.cpu().numpy()\n",
    "\n",
    "            frame_mean, frame_std, frame_labels = get_frame_metrics(output, sample, labels, window_len)\n",
    "            mean_window_error, std_window_error, window_labels = get_window_metrics(output, sample, labels, window_len)\n",
    "            frame_stats.append([frame_mean, frame_std, frame_labels])\n",
    "            window_stats.append([mean_window_error, std_window_error, window_labels])\n",
    "            '''\n",
    "            if j % 50 == 0:\n",
    "                animate(sample[0, :, :, :, :], output[0, :, :, :, :], frame_mean, dset, start_time)\n",
    "            '''\n",
    "            \n",
    "\n",
    "    return(frame_stats, window_stats)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-15-14-06-14\nModels\\Edits/ZED_DepthFair_RegularLoss2021-01-15-14-06-14\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6d3422932a38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#filepath = 'Models\\Edits\\ONI_IRRegularLoss2020-12-15-20-23-58'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manimate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-42bc98caa1f7>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# ===================log========================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch [{}/{}], loss:{:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# save the model each epoch at location filepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = str(datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "print(start_time)\n",
    "filepath = (\n",
    "    \"Models\\\\\"\n",
    "    + dset \n",
    "    + 'Fair_'\n",
    "    + 'RegularLoss'\n",
    "    + start_time\n",
    ")\n",
    "#filepath = 'Models\\Edits\\ONI_IRRegularLoss2020-12-15-20-23-58'\n",
    "print(filepath)\n",
    "train_model(filepath)\n",
    "import functions\n",
    "from functions import animate\n",
    "\n",
    "frame_stats, window_stats = foward_pass(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(180, 5, 8)\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "from functions import get_total_performance_metrics\n",
    "from importlib import reload\n",
    "reload(functions)\n",
    "from functions import get_total_performance_metrics\n",
    "\n",
    "get_total_performance_metrics(frame_stats, window_stats, window_len)\n",
    "\n",
    "\n",
    "#get_total_performance_metrics(originals, reconstruced, testing_labels, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}